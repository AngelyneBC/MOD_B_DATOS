{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV a txts\n",
    "\n",
    "Vamos a generar los inserts para las tablas de Autosummit Perú SAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrir CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ASP = pd.read_csv('ASP.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                (42206340) DANIELLA MARIA BOLAÑOS GAMERO\n",
       "1                         (20100115663) PANDERO S.A. EAFC\n",
       "2       (09468059) KATIA NATHALI DE LOAYZA WONG DE PAC...\n",
       "3        (46472213) JHONATHAN MITCHELL ANTEZANA ESCALANTE\n",
       "4                (42607724) KRISCIA ZULAY REATEGUI ZAMORA\n",
       "                              ...                        \n",
       "1253                                                  NaN\n",
       "1254                                                  NaN\n",
       "1255                                                  NaN\n",
       "1256                                                  NaN\n",
       "1257                                                  NaN\n",
       "Name: Cliente, Length: 1258, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_ASP['Cliente']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Filtrado de colores</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_rep = ds_ASP['Color']\n",
    "colors = []\n",
    "\n",
    "for c in colors_rep:\n",
    "    if isinstance(c, str) and c.strip() != '' and c.lower() != 'nan':\n",
    "        if c not in colors:\n",
    "            colors.append(c)\n",
    "\n",
    "colors = sorted(colors)\n",
    "\n",
    "text_colors = '-- migrate:up\\n\\n'\n",
    "id = 1\n",
    "\n",
    "for c in colors:\n",
    "    c_escaped = c.replace(\"'\", \"''\")\n",
    "    text_colors += f\"INSERT INTO colors (id, nombre) VALUES ({id}, '{c_escaped}');\\n\"\n",
    "    id += 1\n",
    "\n",
    "text_colors += '\\n-- migrate:down\\nDELETE FROM colors;'\n",
    "with open('inserts_colors.sql', 'w') as f:\n",
    "    f.write(text_colors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Filtrado por Asesor </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "asesores_rep = ds_ASP['Asesor']\n",
    "asesores = []\n",
    "\n",
    "#En caso tenga nombres \"raros\" el asesor\n",
    "PALABRAS_INVALIDAS = {\n",
    "    \"PDI\", \"EXHIBICION\", \"ATE\", \"CASO\", \"ENTREGA\"\n",
    "}\n",
    "\n",
    "#Almacenar todo en diccionario - para evitar duplicados\n",
    "asesores = {} \n",
    "\n",
    "def es_asesor_valido(texto):\n",
    "    if not isinstance(texto, str):\n",
    "        return False\n",
    "\n",
    "    texto = texto.strip().upper()\n",
    "\n",
    "    # Debe tener al menos un espacio (nombre + apellido)\n",
    "    if \" \" not in texto:\n",
    "        return False\n",
    "\n",
    "    # No debe contener comas ni números\n",
    "    if \",\" in texto or re.search(r\"\\d\", texto):\n",
    "        return False\n",
    "\n",
    "    # No debe contener palabras inválidas\n",
    "    for palabra in PALABRAS_INVALIDAS:\n",
    "        if palabra in texto:\n",
    "            return False\n",
    "\n",
    "    # Solo letras y espacios\n",
    "    if not re.match(r\"^[A-ZÁÉÍÓÚÑ ]+$\", texto):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "for c in asesores_rep:\n",
    "    if not es_asesor_valido(c):\n",
    "        continue\n",
    "\n",
    "    c = c.strip().upper()\n",
    "    nombres, apellidos = c.split(\" \", 1)\n",
    "\n",
    "    key = (nombres, apellidos)\n",
    "    asesores[key] = True\n",
    "\n",
    "sql_asesores = \"-- migrate:up\\n\\n\"\n",
    "id_asesor = 1\n",
    "\n",
    "for nombres, apellidos in sorted(asesores.keys()):\n",
    "    sql_asesores += (\n",
    "        \"INSERT INTO asesores (id, nombres, apellidos) \"\n",
    "        f\"VALUES ({id_asesor}, '{nombres}', '{apellidos}');\\n\"\n",
    "    )\n",
    "    id_asesor += 1\n",
    "\n",
    "sql_asesores += \"\\n-- migrate:down\\nDELETE FROM asesores;\\n\"\n",
    "\n",
    "with open(\"inserts_asesores.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_asesores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Descomposición en marca (nombre) y modelo (nombre, version, año)</h3>\n",
    "\n",
    "<p> Considerar que Marca no está de forma explícita en el CSV. Solución: inferir y filtrar con diccionarios </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# =========================\n",
    "# 1. COLUMNA CSV\n",
    "# =========================\n",
    "modelos_rep = ds_ASP['Modelo']\n",
    "\n",
    "# Diccionarios (evitan duplicados automáticamente)\n",
    "marcas = {}      # { \"FORD\": 1 }\n",
    "modelos = {}     # { (modelo_base, version, traccion, anio, motor, marca): True }\n",
    "\n",
    "# =========================\n",
    "# CATÁLOGOS CONTROLADOS\n",
    "# =========================\n",
    "MAPA_MARCAS = {\n",
    "    \"FORD\": [\n",
    "        \"TERRITORY\", \"RANGER\", \"F-150\", \"MAVERICK\",\n",
    "        \"EXPLORER\", \"ESCAPE\", \"BRONCO\",\n",
    "        \"MUSTANG\", \"EXPEDITION\"\n",
    "    ],\n",
    "    \"CHERY\": [\n",
    "        \"TIGGO\", \"ARRIZO\", \"M7\", \"HIMLA\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "VERSIONES_VALIDAS = {\n",
    "    \"TITANIUM\", \"TREND\", \"XLS\", \"XLT\", \"XL\", \"LTD\",\n",
    "    \"PLATINUM\", \"RAPTOR\", \"BADLANDS\", \"LARIAT\",\n",
    "    \"ACTIVE\", \"ST\", \"PREMIUM\", \"PRO\", \"MAX\",\n",
    "    \"BIG\", \"BEND\", \"TREMOR\", \"GT\"\n",
    "}\n",
    "\n",
    "TRACCIONES = {\"4X2\", \"4X4\", \"AWD\", \"4WD\"}\n",
    "DESCARTES = {\"MT\", \"AT\", \"CVT\", \"DCT\", \"FHEV\", \"MHEV\", \"PHEV\", \"GLP\", \"GNV\"}\n",
    "\n",
    "# =========================\n",
    "# FUNCIONES\n",
    "# =========================\n",
    "\n",
    "def detectar_marca(texto: str):\n",
    "    texto = texto.upper()\n",
    "    for marca, modelos in MAPA_MARCAS.items():\n",
    "        for m in modelos:\n",
    "            if m in texto:\n",
    "                return marca\n",
    "    return None\n",
    "\n",
    "\n",
    "def extraer_anio(texto: str):\n",
    "    match = re.search(r\"(20\\d{2})\", texto)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "\n",
    "def separar_modelo(texto: str):\n",
    "    tokens = texto.upper().split()\n",
    "\n",
    "    motor = None\n",
    "    traccion = None\n",
    "    usados = set()\n",
    "\n",
    "    for t in tokens:\n",
    "        # Motor (1.5L, 2.0T, etc.)\n",
    "        if re.match(r\"\\d\\.\\d(T|L)?\", t):\n",
    "            motor = float(re.findall(r\"\\d\\.\\d\", t)[0])\n",
    "            usados.add(t)\n",
    "\n",
    "        # Tracción\n",
    "        elif t in TRACCIONES:\n",
    "            traccion = t\n",
    "            usados.add(t)\n",
    "\n",
    "        # Tokens técnicos descartables\n",
    "        elif t in DESCARTES:\n",
    "            usados.add(t)\n",
    "\n",
    "    # limpiar tokens ya usados\n",
    "    limpio = [t for t in tokens if t not in usados]\n",
    "\n",
    "    modelo_base = limpio[0]\n",
    "    version_tokens = [t for t in limpio[1:] if t in VERSIONES_VALIDAS]\n",
    "    version_modelo = \" \".join(version_tokens)\n",
    "\n",
    "    return modelo_base, version_modelo, traccion, motor\n",
    "\n",
    "# =========================\n",
    "# PROCESAMIENTO DEL CSV\n",
    "# =========================\n",
    "\n",
    "for fila in modelos_rep:\n",
    "    if not isinstance(fila, str) or fila.strip() == \"\":\n",
    "        continue\n",
    "\n",
    "    fila = fila.strip().upper()\n",
    "\n",
    "    marca = detectar_marca(fila)\n",
    "    anio = extraer_anio(fila)\n",
    "\n",
    "    if not marca or not anio:\n",
    "        continue\n",
    "\n",
    "    modelo_base, version, traccion, motor = separar_modelo(fila)\n",
    "\n",
    "    if not all([modelo_base, version, traccion, motor]):\n",
    "        continue\n",
    "\n",
    "    # registrar marca (PK lógica)\n",
    "    if marca not in marcas:\n",
    "        marcas[marca] = len(marcas) + 1\n",
    "\n",
    "    key = (modelo_base, version, traccion, anio, motor, marca)\n",
    "    modelos[key] = True\n",
    "\n",
    "# =========================\n",
    "# SQL: MARCAS\n",
    "# =========================\n",
    "\n",
    "sql_marcas = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for marca, id_marca in marcas.items():\n",
    "    sql_marcas += (\n",
    "        f\"INSERT INTO marcas (id_marca, nombre) \"\n",
    "        f\"VALUES ({id_marca}, '{marca}');\\n\"\n",
    "    )\n",
    "\n",
    "sql_marcas += \"\\n-- migrate:down\\nDELETE FROM marcas;\\n\"\n",
    "\n",
    "with open(\"inserts_marcas.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_marcas)\n",
    "\n",
    "# =========================\n",
    "# SQL: MODELOS\n",
    "# =========================\n",
    "\n",
    "sql_modelos = \"-- migrate:up\\n\\n\"\n",
    "id_modelo = 1\n",
    "\n",
    "for (modelo_base, version, traccion, anio, motor, marca) in modelos.keys():\n",
    "    marca_id = marcas[marca]\n",
    "\n",
    "    sql_modelos += (\n",
    "        \"INSERT INTO modelos \"\n",
    "        \"(id_modelo, modelo_base, version_modelo, traccion, anio, motor, marca_id) \"\n",
    "        f\"VALUES ({id_modelo}, '{modelo_base}', '{version}', \"\n",
    "        f\"'{traccion}', {anio}, {motor}, {marca_id});\\n\"\n",
    "    )\n",
    "    id_modelo += 1\n",
    "\n",
    "sql_modelos += \"\\n-- migrate:down\\nDELETE FROM modelos;\\n\"\n",
    "\n",
    "with open(\"inserts_modelos.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_modelos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Filtrado de GPS</h2>\n",
    "<p>Eliminar si tiene la palabra \"GPS\" para dejar el resto del texto </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def limpiar_gps(texto):\n",
    "    if not isinstance(texto, str):\n",
    "        return None\n",
    "\n",
    "    texto = texto.strip().upper()\n",
    "\n",
    "    # Eliminar fechas entre paréntesis\n",
    "    texto = re.sub(r\"\\(.*?\\)\", \"\", texto)\n",
    "\n",
    "    return texto.strip()\n",
    "\n",
    "ds = pd.read_csv(\"ASP.csv\", encoding=\"utf-8\")\n",
    "\n",
    "gps_dict = {}\n",
    "id_gps = 1\n",
    "\n",
    "for g in ds['GPS']:\n",
    "    nombre = limpiar_gps(g)\n",
    "    if not nombre:\n",
    "        continue\n",
    "\n",
    "    if nombre not in gps_dict:\n",
    "        gps_dict[nombre] = id_gps\n",
    "        id_gps += 1\n",
    "\n",
    "# Generar SQL GPS\n",
    "\n",
    "sql_gps = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for nombre, id_ in gps_dict.items():\n",
    "    sql_gps += (\n",
    "        \"INSERT INTO gps (id, nombre) \"\n",
    "        f\"VALUES ({id_}, '{nombre}');\\n\"\n",
    "    )\n",
    "\n",
    "sql_gps += \"\\n-- migrate:down\\nDELETE FROM gps;\\n\"\n",
    "\n",
    "with open(\"inserts_gps.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_gps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Filtrado de Clientes </h2>\n",
    "<p>Al estar en cliente el nombre de empresa / persona natural + DNI/RUC El objetivos principal será separar número de identificación de identidad y el nombre, así como clasificar en caso sea persona natural o empresa </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "clientes_rep = ds_ASP['Cliente']\n",
    "\n",
    "# ===================== FUNCIONES =====================\n",
    "\n",
    "def limpiar_cliente(texto):\n",
    "    \"\"\"\n",
    "    (20100115663) PANDERO S.A. EAFC\n",
    "    \"\"\"\n",
    "    if not isinstance(texto, str):\n",
    "        return None, None\n",
    "\n",
    "    texto = texto.strip()\n",
    "\n",
    "    match = re.match(r\"\\((\\d+)\\)\\s*(.+)\", texto)\n",
    "    if not match:\n",
    "        return None, None\n",
    "\n",
    "    numero = match.group(1)\n",
    "    nombre = match.group(2).strip().upper()\n",
    "\n",
    "    return numero, nombre\n",
    "\n",
    "\n",
    "PALABRAS_EMPRESA = {\n",
    "    \"S.A\", \"S.A.\", \"S.A.C\", \"SAC\", \"SOCIEDAD\",\n",
    "    \"EMPRESA\", \"E.A.F.C\", \"EAFC\", \"CORPORACION\",\n",
    "    \"GRUPO\", \"GROUP\", \"E.I.R.L\", \"SERVICIOS\",\n",
    "    \"SRL\", \"S.R.L\"\n",
    "}\n",
    "\n",
    "def es_empresa(nombre):\n",
    "    return any(p in nombre for p in PALABRAS_EMPRESA)\n",
    "\n",
    "\n",
    "# ===================== ESTRUCTURAS =====================\n",
    "\n",
    "clientes = {}          # id_cliente -> (numero, nombre)\n",
    "personas = set()       # ids\n",
    "empresas = set()       # ids\n",
    "\n",
    "id_cliente = 1\n",
    "\n",
    "# ===================== PROCESAMIENTO =====================\n",
    "\n",
    "for fila in clientes_rep:\n",
    "    numero, nombre = limpiar_cliente(fila)\n",
    "\n",
    "    if not numero or not nombre:\n",
    "        continue\n",
    "\n",
    "    clientes[id_cliente] = (numero, nombre)\n",
    "\n",
    "    if es_empresa(nombre):\n",
    "        empresas.add(id_cliente)\n",
    "    else:\n",
    "        personas.add(id_cliente)\n",
    "\n",
    "    id_cliente += 1\n",
    "\n",
    "\n",
    "# ===================== SQL CLIENTES =====================\n",
    "\n",
    "sql_clientes = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for id_cliente, (numero, nombre) in clientes.items():\n",
    "    nombre = nombre.replace(\"'\", \"''\")\n",
    "    sql_clientes += (\n",
    "        \"INSERT INTO clientes (id_cliente, Numero_Identificacion, nombre) \"\n",
    "        f\"VALUES ({id_cliente}, '{numero}', '{nombre}');\\n\"\n",
    "    )\n",
    "\n",
    "sql_clientes += \"\\n-- migrate:down\\nDELETE FROM clientes;\\n\"\n",
    "\n",
    "with open(\"inserts_clientes.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_clientes)\n",
    "\n",
    "\n",
    "# ===================== SQL PERSONA NATURAL =====================\n",
    "\n",
    "sql_personas = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for id_cliente in personas:\n",
    "    sql_personas += (\n",
    "        \"INSERT INTO persona_natural (id_persona, cliente_id) \"\n",
    "        f\"VALUES ({id_cliente}, {id_cliente});\\n\"\n",
    "    )\n",
    "\n",
    "sql_personas += \"\\n-- migrate:down\\nDELETE FROM persona_natural;\\n\"\n",
    "\n",
    "with open(\"inserts_persona_natural.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_personas)\n",
    "\n",
    "\n",
    "# ===================== SQL EMPRESA =====================\n",
    "\n",
    "sql_empresas = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for id_cliente in empresas:\n",
    "    sql_empresas += (\n",
    "        \"INSERT INTO empresa (id_empresa, cliente_id) \"\n",
    "        f\"VALUES ({id_cliente}, {id_cliente});\\n\"\n",
    "    )\n",
    "\n",
    "sql_empresas += \"\\n-- migrate:down\\nDELETE FROM empresa;\\n\"\n",
    "\n",
    "with open(\"inserts_empresa.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_empresas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrado vehiculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'colores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (placa \u001b[38;5;129;01mand\u001b[39;00m vin \u001b[38;5;129;01mand\u001b[39;00m color \u001b[38;5;129;01mand\u001b[39;00m modelo \u001b[38;5;129;01mand\u001b[39;00m dni):\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m color_id = \u001b[43mcolores\u001b[49m[color]\n\u001b[32m     22\u001b[39m modelo_id = modelos[modelo]\n\u001b[32m     23\u001b[39m cliente_id = dict_cliente[dni]\n",
      "\u001b[31mNameError\u001b[39m: name 'colores' is not defined"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# VEHICULOS\n",
    "# ===============================\n",
    "\n",
    "sql_vehiculos = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for _, row in ds.iterrows():\n",
    "\n",
    "    placa = str(row['PLACA']).strip()\n",
    "    vin = str(row['VIN']).strip()\n",
    "\n",
    "    color = str(row['Color']).strip().upper()\n",
    "    modelo = str(row['Modelo']).strip().upper()\n",
    "\n",
    "    dni, _ = limpiar_cliente(row['Cliente'])\n",
    "    gps = limpiar_gps(row['GPS'])\n",
    "\n",
    "    if not (placa and vin and color and modelo and dni):\n",
    "        continue\n",
    "\n",
    "    color_id = colores[color]\n",
    "    modelo_id = modelos[modelo]\n",
    "    cliente_id = dict_cliente[dni]\n",
    "    gps_id = gps_dict.get(gps, \"NULL\")\n",
    "\n",
    "    sql_vehiculos += (\n",
    "        \"INSERT INTO vehiculos \"\n",
    "        \"(placa, vin, color_id, modelo_id, cliente_id, gps_id) \"\n",
    "        f\"VALUES ('{placa}', '{vin}', {color_id}, {modelo_id}, {cliente_id}, {gps_id});\\n\"\n",
    "    )\n",
    "\n",
    "sql_vehiculos += \"\\n-- migrate:down\\nDELETE FROM vehiculos;\\n\"\n",
    "\n",
    "with open(\"inserts_vehiculos.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_vehiculos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrado de recepciones_campañas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ===============================\n",
    "# Cargar dataset\n",
    "# ===============================\n",
    "\n",
    "ds = pd.read_csv(\"ASP.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# ===============================\n",
    "# CAMPAÑAS\n",
    "# ===============================\n",
    "\n",
    "campanias = {}\n",
    "id_campania = 1\n",
    "\n",
    "for c in ds['CAMPAÑA']:\n",
    "    if not isinstance(c, str):\n",
    "        continue\n",
    "\n",
    "    c = c.strip().upper()\n",
    "\n",
    "    if c and c not in campanias:\n",
    "        campanias[c] = id_campania\n",
    "        id_campania += 1\n",
    "\n",
    "# ===============================\n",
    "# RECEPCIONES\n",
    "# ===============================\n",
    "\n",
    "recepciones = {}\n",
    "id_recepcion = 1\n",
    "\n",
    "for f in ds['FECHA DE RECEPCION DEL VEHICULO']:\n",
    "    if pd.isna(f):\n",
    "        continue\n",
    "\n",
    "    f = str(f).strip()\n",
    "\n",
    "    if f not in recepciones:\n",
    "        recepciones[f] = id_recepcion\n",
    "        id_recepcion += 1\n",
    "\n",
    "# ===============================\n",
    "# RELACION N:M\n",
    "# ===============================\n",
    "\n",
    "relaciones = set()\n",
    "\n",
    "for _, row in ds.iterrows():\n",
    "\n",
    "    camp = str(row['CAMPAÑA']).strip().upper()\n",
    "    fecha = str(row['FECHA DE RECEPCION DEL VEHICULO']).strip()\n",
    "\n",
    "    if not camp or camp == \"NAN\" or not fecha or fecha == \"NAN\":\n",
    "        continue\n",
    "\n",
    "    relaciones.add((campanias[camp], recepciones[fecha]))\n",
    "\n",
    "# ===============================\n",
    "# GENERAR SQL\n",
    "# ===============================\n",
    "\n",
    "sql_rel = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for camp_id, rec_id in sorted(relaciones):\n",
    "    sql_rel += (\n",
    "        \"INSERT INTO recepciones_campañas (campañas_id, recepciones_id) \"\n",
    "        f\"VALUES ({camp_id}, {rec_id});\\n\"\n",
    "    )\n",
    "\n",
    "sql_rel += \"\\n-- migrate:down\\nDELETE FROM recepciones_campañas;\\n\"\n",
    "\n",
    "with open(\"inserts_recepciones_campañas.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_rel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrado de ubicaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ===============================\n",
    "# Cargar dataset\n",
    "# ===============================\n",
    "\n",
    "ds = pd.read_csv(\"ASP.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# ===============================\n",
    "# LIMPIEZA\n",
    "# ===============================\n",
    "\n",
    "def limpiar_texto(txt):\n",
    "    if not isinstance(txt, str):\n",
    "        return None\n",
    "    return txt.strip().upper()\n",
    "\n",
    "# ===============================\n",
    "# DISTRITOS (CATALOGO)\n",
    "# ===============================\n",
    "\n",
    "distritos = {}\n",
    "id_distrito = 1\n",
    "\n",
    "for u in ds['UBICACIÓN']:\n",
    "    u = limpiar_texto(u)\n",
    "    if not u:\n",
    "        continue\n",
    "\n",
    "    if u not in distritos:\n",
    "        distritos[u] = id_distrito\n",
    "        id_distrito += 1\n",
    "\n",
    "# ===============================\n",
    "# UBICACIONES\n",
    "# ===============================\n",
    "\n",
    "ubicaciones = {}\n",
    "\n",
    "for u in ds['UBICACIÓN']:\n",
    "    u = limpiar_texto(u)\n",
    "    if not u:\n",
    "        continue\n",
    "\n",
    "    ubicaciones[u] = distritos[u]\n",
    "\n",
    "# ===============================\n",
    "# SQL DISTRITOS\n",
    "# ===============================\n",
    "\n",
    "sql_distritos = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for nombre, id_ in distritos.items():\n",
    "    sql_distritos += (\n",
    "        \"INSERT INTO distritos (id, nombre) \"\n",
    "        f\"VALUES ({id_}, '{nombre}');\\n\"\n",
    "    )\n",
    "\n",
    "sql_distritos += \"\\n-- migrate:down\\nDELETE FROM distritos;\\n\"\n",
    "\n",
    "with open(\"inserts_distritos.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_distritos)\n",
    "\n",
    "# ===============================\n",
    "# SQL UBICACIONES\n",
    "# ===============================\n",
    "\n",
    "sql_ubicaciones = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for ubicacion, distrito_id in ubicaciones.items():\n",
    "    sql_ubicaciones += (\n",
    "        \"INSERT INTO ubicaciones (ubicacion, distritos_id) \"\n",
    "        f\"VALUES ('{ubicacion}', {distrito_id});\\n\"\n",
    "    )\n",
    "\n",
    "sql_ubicaciones += \"\\n-- migrate:down\\nDELETE FROM ubicaciones;\\n\"\n",
    "\n",
    "with open(\"inserts_ubicaciones.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_ubicaciones)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
