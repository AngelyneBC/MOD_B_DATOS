{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV a txts\n",
    "\n",
    "Vamos a generar los inserts para las tablas de Autosummit Perú SAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrir CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ASP = pd.read_csv('ASP.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                (42206340) DANIELLA MARIA BOLAÑOS GAMERO\n",
       "1                         (20100115663) PANDERO S.A. EAFC\n",
       "2       (09468059) KATIA NATHALI DE LOAYZA WONG DE PAC...\n",
       "3        (46472213) JHONATHAN MITCHELL ANTEZANA ESCALANTE\n",
       "4                (42607724) KRISCIA ZULAY REATEGUI ZAMORA\n",
       "                              ...                        \n",
       "1253                                                  NaN\n",
       "1254                                                  NaN\n",
       "1255                                                  NaN\n",
       "1256                                                  NaN\n",
       "1257                                                  NaN\n",
       "Name: Cliente, Length: 1258, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_ASP['Cliente']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Filtrado de colores</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_rep = ds_ASP['Color']\n",
    "colors_diccionario = {}  # color limpio -> id_color\n",
    "id_color = 1\n",
    "\n",
    "for c in colors_rep:\n",
    "    if isinstance(c, str) and c.strip() != '' and c.lower() != 'nan':\n",
    "        color = c.strip().upper()\n",
    "        if color not in colors_diccionario:\n",
    "            colors_diccionario[color] = id_color\n",
    "            id_color += 1\n",
    "\n",
    "text_colors = '-- migrate:up\\n\\n'\n",
    "for color, id_color in colors_diccionario.items():\n",
    "    c_escaped = color.replace(\"'\", \"''\")\n",
    "    text_colors += f\"INSERT INTO color (id_color, nombre) VALUES ({id_color}, '{c_escaped}');\\n\"\n",
    "\n",
    "text_colors += '\\n-- migrate:down\\nDELETE FROM color;'\n",
    "\n",
    "with open('inserts_colors.sql', 'w', encoding='utf-8') as f:\n",
    "    f.write(text_colors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Filtrado por Asesor </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "asesores_rep = ds_ASP['Asesor']\n",
    "asesores = []\n",
    "\n",
    "#En caso tenga nombres \"raros\" el asesor\n",
    "PALABRAS_INVALIDAS = {\n",
    "    \"PDI\", \"EXHIBICION\", \"ATE\", \"CASO\", \"ENTREGA\"\n",
    "}\n",
    "\n",
    "#Almacenar todo en diccionario - para evitar duplicados\n",
    "asesores = {} \n",
    "\n",
    "def es_asesor_valido(texto):\n",
    "    if not isinstance(texto, str):\n",
    "        return False\n",
    "\n",
    "    texto = texto.strip().upper()\n",
    "\n",
    "    # Debe tener al menos un espacio (nombre + apellido)\n",
    "    if \" \" not in texto:\n",
    "        return False\n",
    "\n",
    "    # No debe contener comas ni números\n",
    "    if \",\" in texto or re.search(r\"\\d\", texto):\n",
    "        return False\n",
    "\n",
    "    # No debe contener palabras inválidas\n",
    "    for palabra in PALABRAS_INVALIDAS:\n",
    "        if palabra in texto:\n",
    "            return False\n",
    "\n",
    "    # Solo letras y espacios\n",
    "    if not re.match(r\"^[A-ZÁÉÍÓÚÑ ]+$\", texto):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "for c in asesores_rep:\n",
    "    if not es_asesor_valido(c):\n",
    "        continue\n",
    "\n",
    "    c = c.strip().upper()\n",
    "    nombres, apellidos = c.split(\" \", 1)\n",
    "\n",
    "    key = (nombres, apellidos)\n",
    "    asesores[key] = True\n",
    "\n",
    "sql_asesores = \"-- migrate:up\\n\\n\"\n",
    "id_asesor = 1\n",
    "#para recepciones\n",
    "asesores_diccionario={}\n",
    "for nombres, apellidos in sorted(asesores.keys()):\n",
    "    nombre_completo = f\"{nombres} {apellidos}\"\n",
    "    sql_asesores += (\n",
    "        \"INSERT INTO asesores (id_asesor, nombres, apellidos) \"\n",
    "        f\"VALUES ({id_asesor}, '{nombres}', '{apellidos}');\\n\"\n",
    "    )\n",
    "    asesores_diccionario[(nombre_completo)] = id_asesor\n",
    "    id_asesor += 1\n",
    "\n",
    "sql_asesores += \"\\n-- migrate:down\\nDELETE FROM asesores;\\n\"\n",
    "\n",
    "with open(\"inserts_asesores.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_asesores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Descomposición en marca (nombre) y modelo (nombre, version, año)</h3>\n",
    "\n",
    "<p> Considerar que Marca no está de forma explícita en el CSV. Solución: inferir y filtrar con diccionarios </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# =========================\n",
    "# 1. COLUMNA CSV\n",
    "# =========================\n",
    "modelos_rep = ds_ASP['Modelo']\n",
    "\n",
    "# Diccionarios con IDs\n",
    "marcas_dict = {}      # marca -> id_marca\n",
    "modelos_dict = {}     # (modelo_base, version, traccion, anio, motor, marca) -> id_modelo\n",
    "id_modelo = 1\n",
    "\n",
    "# =========================\n",
    "# CATÁLOGOS CONTROLADOS\n",
    "# =========================\n",
    "MAPA_MARCAS = {\n",
    "    \"FORD\": [\n",
    "        \"TERRITORY\", \"RANGER\", \"F-150\", \"MAVERICK\",\n",
    "        \"EXPLORER\", \"ESCAPE\", \"BRONCO\",\n",
    "        \"MUSTANG\", \"EXPEDITION\"\n",
    "    ],\n",
    "    \"CHERY\": [\n",
    "        \"TIGGO\", \"ARRIZO\", \"M7\", \"HIMLA\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "VERSIONES_VALIDAS = {\n",
    "    \"TITANIUM\", \"TREND\", \"XLS\", \"XLT\", \"XL\", \"LTD\",\n",
    "    \"PLATINUM\", \"RAPTOR\", \"BADLANDS\", \"LARIAT\",\n",
    "    \"ACTIVE\", \"ST\", \"PREMIUM\", \"PRO\", \"MAX\",\n",
    "    \"BIG\", \"BEND\", \"TREMOR\", \"GT\"\n",
    "}\n",
    "\n",
    "TRACCIONES = {\"4X2\", \"4X4\", \"AWD\", \"4WD\"}\n",
    "DESCARTES = {\"MT\", \"AT\", \"CVT\", \"DCT\", \"FHEV\", \"MHEV\", \"PHEV\", \"GLP\", \"GNV\"}\n",
    "\n",
    "# =========================\n",
    "# FUNCIONES\n",
    "# =========================\n",
    "\n",
    "def detectar_marca(texto: str):\n",
    "    texto = texto.upper()\n",
    "    for marca, modelos in MAPA_MARCAS.items():\n",
    "        for m in modelos:\n",
    "            if m in texto:\n",
    "                return marca\n",
    "    return None\n",
    "\n",
    "def extraer_anio(texto: str):\n",
    "    match = re.search(r\"(20\\d{2})\", texto)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def separar_modelo(texto: str):\n",
    "    tokens = texto.upper().split()\n",
    "    motor = None\n",
    "    traccion = None\n",
    "    usados = set()\n",
    "\n",
    "    for t in tokens:\n",
    "        # Motor (1.5L, 2.0T, etc.)\n",
    "        if re.match(r\"\\d\\.\\d(T|L)?\", t):\n",
    "            motor = float(re.findall(r\"\\d\\.\\d\", t)[0])\n",
    "            usados.add(t)\n",
    "\n",
    "        # Tracción\n",
    "        elif t in TRACCIONES:\n",
    "            traccion = t\n",
    "            usados.add(t)\n",
    "\n",
    "        # Tokens técnicos descartables\n",
    "        elif t in DESCARTES:\n",
    "            usados.add(t)\n",
    "\n",
    "    # limpiar tokens ya usados\n",
    "    limpio = [t for t in tokens if t not in usados]\n",
    "    modelo_base = limpio[0] if limpio else None\n",
    "    version_tokens = [t for t in limpio[1:] if t in VERSIONES_VALIDAS]\n",
    "    version_modelo = \" \".join(version_tokens) if version_tokens else None\n",
    "\n",
    "    return modelo_base, version_modelo, traccion, motor\n",
    "\n",
    "# =========================\n",
    "# PROCESAMIENTO DEL CSV\n",
    "# =========================\n",
    "for fila in modelos_rep:\n",
    "    if not isinstance(fila, str) or fila.strip() == \"\":\n",
    "        continue\n",
    "\n",
    "    fila = fila.strip().upper()\n",
    "    marca = detectar_marca(fila)\n",
    "    anio = extraer_anio(fila)\n",
    "\n",
    "    if not marca or not anio:\n",
    "        continue\n",
    "\n",
    "    modelo_base, version, traccion, motor = separar_modelo(fila)\n",
    "    if not all([modelo_base, version, traccion, motor]):\n",
    "        continue\n",
    "\n",
    "    # Registrar marca con ID\n",
    "    if marca not in marcas_dict:\n",
    "        marcas_dict[marca] = len(marcas_dict) + 1\n",
    "    marca_id = marcas_dict[marca]\n",
    "\n",
    "    # Registrar modelo con ID\n",
    "    key = (modelo_base, version, traccion, anio, motor, marca)\n",
    "    if key not in modelos_dict:\n",
    "        modelos_dict[key] = id_modelo\n",
    "        id_modelo += 1\n",
    "\n",
    "# =========================\n",
    "# SQL: MARCAS\n",
    "# =========================\n",
    "sql_marcas = \"-- migrate:up\\n\\n\"\n",
    "for marca, id_marca in marcas_dict.items():\n",
    "    c_escaped = marca.replace(\"'\", \"''\")\n",
    "    sql_marcas += f\"INSERT INTO marcas (id_marca, nombre) VALUES ({id_marca}, '{c_escaped}');\\n\"\n",
    "\n",
    "sql_marcas += \"\\n-- migrate:down\\nDELETE FROM marcas;\\n\"\n",
    "\n",
    "with open(\"inserts_marcas.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_marcas)\n",
    "\n",
    "# =========================\n",
    "# SQL: MODELOS\n",
    "# =========================\n",
    "sql_modelos = \"-- migrate:up\\n\\n\"\n",
    "for (modelo_base, version, traccion, anio, motor, marca), id_modelo in modelos_dict.items():\n",
    "    marca_id = marcas_dict[marca]\n",
    "    modelo_base_esc = modelo_base.replace(\"'\", \"''\")\n",
    "    version_esc = version.replace(\"'\", \"''\") if version else ''\n",
    "    traccion_esc = traccion.replace(\"'\", \"''\") if traccion else ''\n",
    "\n",
    "    sql_modelos += (\n",
    "        \"INSERT INTO modelos \"\n",
    "        \"(id_modelo, modelo_base, version_modelo, traccion, anio, motor, marca_id) \"\n",
    "        f\"VALUES ({id_modelo}, '{modelo_base_esc}', '{version_esc}', \"\n",
    "        f\"'{traccion_esc}', {anio}, {motor}, {marca_id});\\n\"\n",
    "    )\n",
    "\n",
    "sql_modelos += \"\\n-- migrate:down\\nDELETE FROM modelos;\\n\"\n",
    "\n",
    "with open(\"inserts_modelos.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Filtrado de GPS</h2>\n",
    "<p>Eliminar si tiene la palabra \"GPS\" para dejar el resto del texto </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def limpiar_gps(texto):\n",
    "    if not isinstance(texto, str):\n",
    "        return None\n",
    "\n",
    "    texto = texto.strip().upper()\n",
    "\n",
    "    # Eliminar fechas entre paréntesis\n",
    "    texto = re.sub(r\"\\(.*?\\)\", \"\", texto)\n",
    "\n",
    "    #Eliminar comentarios\n",
    "    texto = re.sub(r\"\\d+/\\d+\", \"\", texto)\n",
    "\n",
    "    #PALABRAS NO ACEPTADAS: Eliminar si existen\n",
    "    FiltroNoAceptado = [\n",
    "        \"OK\", \"INSTALADO\", \"COORDINAR\", \"CLIENTE\",\n",
    "        \"NO APLICA\", \"CAMPAÑA\", \"AUTOPLAN\"\n",
    "    ]\n",
    "\n",
    "    for palabra in FiltroNoAceptado:\n",
    "        texto = texto.replace(palabra, \"\")\n",
    "\n",
    "    #Solo queremos letras y espacios\n",
    "    texto = re.sub(r\"[^A-Z ]\", \"\", texto)\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
    "\n",
    "    return texto #La versión limpia del texto que pasa\n",
    "\n",
    "def detectar_gps_base(texto):\n",
    "    GPS_VALIDOS = {\"COMSATEL\",\"HUNTER\", \"SUPRA\",\"PANDERO\", \"PROTEMAX\", \"MAQUISISTEMAS\",\"EURORENTING\"}\n",
    "    \n",
    "    # Forma limpia: 'GPS {PALABRACLAVE}'\n",
    "    for palabraGPS in GPS_VALIDOS:\n",
    "        if palabraGPS in texto: \n",
    "            return f\"GPS {palabraGPS}\"\n",
    "    return None #Si no encaja, no es válido\n",
    "\n",
    "ds = pd.read_csv(\"ASP.csv\", encoding=\"utf-8\")\n",
    "\n",
    "gps_dict = {}\n",
    "id_gps = 1\n",
    "\n",
    "for g in ds['GPS']:\n",
    "    nombreGPSLimpio = limpiar_gps(g)\n",
    "    if not nombreGPSLimpio:\n",
    "        continue\n",
    "\n",
    "    gps_base = detectar_gps_base(nombreGPSLimpio)\n",
    "\n",
    "    if not gps_base:\n",
    "        continue \n",
    "\n",
    "    if gps_base not in gps_dict:\n",
    "        gps_dict[gps_base] = id_gps\n",
    "        id_gps += 1\n",
    "\n",
    "# Generar SQL GPS\n",
    "\n",
    "sql_gps = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for nombre, id_ in gps_dict.items():\n",
    "    sql_gps += (\n",
    "        \"INSERT INTO gps (id_gps, nombre) \"\n",
    "        f\"VALUES ({id_}, '{nombre}');\\n\"\n",
    "    )\n",
    "\n",
    "sql_gps += \"\\n-- migrate:down\\nDELETE FROM gps;\\n\"\n",
    "\n",
    "with open(\"inserts_gps.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_gps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Filtrado de Clientes </h2>\n",
    "<p>Al estar en cliente el nombre de empresa / persona natural + DNI/RUC El objetivos principal será separar número de identificación de identidad y el nombre, así como clasificar en caso sea persona natural o empresa </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "clientes_rep = ds_ASP['Cliente']\n",
    "\n",
    "# ===================== FUNCIONES =====================\n",
    "\n",
    "def limpiar_cliente(texto):\n",
    "    \"\"\"\n",
    "    (20100115663) PANDERO S.A. EAFC\n",
    "    \"\"\"\n",
    "    if not isinstance(texto, str):\n",
    "        return None, None\n",
    "\n",
    "    texto = texto.strip()\n",
    "\n",
    "    match = re.match(r\"\\((\\d+)\\)\\s*(.+)\", texto)\n",
    "    if not match:\n",
    "        return None, None\n",
    "\n",
    "    numero = match.group(1)\n",
    "    nombre = match.group(2).strip().upper()\n",
    "\n",
    "    return numero, nombre\n",
    "\n",
    "\n",
    "PALABRAS_EMPRESA = {\n",
    "    \"S.A\", \"S.A.\", \"S.A.C\", \"SAC\", \"SOCIEDAD\",\n",
    "    \"EMPRESA\", \"E.A.F.C\", \"EAFC\", \"CORPORACION\",\n",
    "    \"GRUPO\", \"GROUP\", \"E.I.R.L\", \"SERVICIOS\",\n",
    "    \"SRL\", \"S.R.L\"\n",
    "}\n",
    "\n",
    "def es_empresa(nombre):\n",
    "    return any(p in nombre for p in PALABRAS_EMPRESA)\n",
    "\n",
    "\n",
    "# ===================== ESTRUCTURAS =====================\n",
    "\n",
    "clientes_dict = {}          # id_cliente -> (numero, nombre)\n",
    "personas = set()       # ids\n",
    "empresas = set()       # ids\n",
    "\n",
    "id_cliente = 1\n",
    "id_persona = 1\n",
    "id_empresa = 1\n",
    "\n",
    "# ===================== PROCESAMIENTO =====================\n",
    "\n",
    "for fila in clientes_rep:\n",
    "    numero, nombre = limpiar_cliente(fila)\n",
    "\n",
    "    if not numero or not nombre:\n",
    "        continue\n",
    "\n",
    "    clientes_dict[id_cliente] = (numero, nombre)\n",
    "\n",
    "    if es_empresa(nombre):\n",
    "        empresas.add(id_cliente)\n",
    "    else:\n",
    "        personas.add(id_cliente)\n",
    "\n",
    "    id_cliente += 1\n",
    "\n",
    "\n",
    "# ===================== SQL CLIENTES =====================\n",
    "\n",
    "sql_clientes = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for id_cliente, (numero, nombre) in clientes_dict.items():\n",
    "    nombre = nombre.replace(\"'\", \"''\")\n",
    "    sql_clientes += (\n",
    "        \"INSERT INTO clientes (id_cliente, Numero_Identificacion, nombre) \"\n",
    "        f\"VALUES ({id_cliente}, '{numero}', '{nombre}');\\n\"\n",
    "    )\n",
    "\n",
    "sql_clientes += \"\\n-- migrate:down\\nDELETE FROM clientes;\\n\"\n",
    "\n",
    "with open(\"inserts_clientes.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_clientes)\n",
    "\n",
    "\n",
    "# ===================== SQL PERSONA NATURAL =====================\n",
    "\n",
    "sql_personas = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for id_cliente in personas:\n",
    "    sql_personas += (\n",
    "        \"INSERT INTO persona_natural (id_persona, cliente_id) \"\n",
    "        f\"VALUES ({id_persona}, {id_cliente});\\n\"\n",
    "    )\n",
    "    id_persona += 1\n",
    "\n",
    "sql_personas += \"\\n-- migrate:down\\nDELETE FROM persona_natural;\\n\"\n",
    "\n",
    "with open(\"inserts_persona_natural.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_personas)\n",
    "\n",
    "\n",
    "# ===================== SQL EMPRESA =====================\n",
    "\n",
    "sql_empresas = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for id_cliente in empresas:\n",
    "    sql_empresas += (\n",
    "        \"INSERT INTO empresa (id_empresa, cliente_id) \"\n",
    "        f\"VALUES ({id_empresa}, {id_cliente});\\n\"\n",
    "    )\n",
    "    id_empresa += 1\n",
    "\n",
    "sql_empresas += \"\\n-- migrate:down\\nDELETE FROM empresa;\\n\"\n",
    "\n",
    "with open(\"inserts_empresa.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_empresas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Filtrado vehiculo</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Dado que vehículo depende de otros: colores, MODELO. GPS, etc. Y esos respectivos datos ya ha ¿n sido filtrados, se reutiliza el coidgo e inserta en diccionarios.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "vehiculos = ds_ASP[['PLACA', 'VIN', 'Color', 'Modelo', 'Cliente', 'GPS']].to_numpy()\n",
    "\n",
    "text = '-- migrate:up\\n\\n'\n",
    "id_vehiculo = 1\n",
    "vehiculos_diccionario = {}\n",
    "\n",
    "def sql_value(v):\n",
    "    if v is None:\n",
    "        return \"NULL\"\n",
    "    return f\"'{v}'\"\n",
    "\n",
    "for n in vehiculos:\n",
    "\n",
    "    placa = str(n[0]).strip().upper() if pd.notna(n[0]) else None\n",
    "    vin = str(n[1]).strip().upper() if pd.notna(n[1]) else None\n",
    "\n",
    "    color_str = str(n[2]).strip().upper() if pd.notna(n[2]) else None\n",
    "    colors_v = colors_diccionario.get(color_str) if color_str else None\n",
    "\n",
    "    gps_v = None\n",
    "    if pd.notna(n[5]):\n",
    "        gps_str = limpiar_gps(str(n[5]))\n",
    "        gps_base = detectar_gps_base(gps_str)\n",
    "        gps_v = gps_dict.get(gps_base)\n",
    "\n",
    "    modelo_v = None\n",
    "    if pd.notna(n[3]):\n",
    "        modelo_str = str(n[3]).strip().upper()\n",
    "        for (modelo, version, traccion, anio, motor, marca), mid in modelos_dict.items():\n",
    "            if modelo.upper() in modelo_str:\n",
    "                modelo_v = mid\n",
    "                break\n",
    "\n",
    "    cliente_v = None\n",
    "    if pd.notna(n[4]):\n",
    "        cliente_str = str(n[4]).strip().upper()\n",
    "        match = re.search(r'\\((\\d+)\\)', cliente_str)\n",
    "        if match:\n",
    "            doc = match.group(1)\n",
    "            for cid, (dni, nombre) in clientes_dict.items():\n",
    "                if dni == doc:\n",
    "                    cliente_v = cid\n",
    "                    break\n",
    "\n",
    "    if cliente_v is None:\n",
    "        continue\n",
    "\n",
    "    valores = [placa, vin, colors_v, modelo_v, gps_v, cliente_v]\n",
    "    if all(v is None for v in valores):\n",
    "        continue\n",
    "\n",
    "    placa_sql = sql_value(placa)\n",
    "    vin_sql = sql_value(vin)\n",
    "    color_sql = colors_v if colors_v is not None else \"NULL\"\n",
    "    modelo_sql = modelo_v if modelo_v is not None else \"NULL\"\n",
    "    gps_sql = gps_v if gps_v is not None else \"NULL\"\n",
    "    cliente_sql = cliente_v if cliente_v is not None else \"NULL\"\n",
    "\n",
    "    text += (\n",
    "        f\"INSERT INTO vehiculos \"\n",
    "        f\"(id_vehiculo, placa, vin, color_id, modelo_id, gps_id, cliente_id) \"\n",
    "        f\"VALUES ({id_vehiculo}, {placa_sql}, {vin_sql}, \"\n",
    "        f\"{color_sql}, {modelo_sql}, {gps_sql}, {cliente_sql});\\n\"\n",
    "    )\n",
    "\n",
    "    vehiculos_diccionario[id_vehiculo] = (\n",
    "        placa,\n",
    "        vin,\n",
    "        colors_v,\n",
    "        modelo_v,\n",
    "        gps_v,\n",
    "        cliente_v\n",
    "    )\n",
    "\n",
    "    id_vehiculo += 1\n",
    "\n",
    "text += '\\n-- migrate:down\\nDELETE FROM vehiculos;\\n'\n",
    "\n",
    "with open('inserts_vehiculos.sql', 'w', encoding='utf-8') as archivo:\n",
    "    archivo.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Distritos y Ubicaciones</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Dada la estructura de los datos, se ha optado por crear un diccionario que asocie cada ubicacion con un distrito, en caso no especifique, se optará por NULL.</p>\n",
    "<p>Primero identificar distritos y luego de ahí obtener ubicaciones</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ubicaciones_rep = ds_ASP['UBICACIÓN']\n",
    "\n",
    "# Diccionarios con IDs\n",
    "distritos_dict = {}           # distrito -> id_distrito\n",
    "ubicaciones_dict = {}         # (ubicacion, distrito_id) -> id_ubicacion\n",
    "\n",
    "id_distrito = 1\n",
    "id_ubicacion = 1\n",
    "\n",
    "# =========================\n",
    "# CATÁLOGOS CONTROLADOS\n",
    "# =========================\n",
    "CATALOGO_DISTRITOS = {\n",
    "    \"ATE\",\n",
    "    \"SAN ISIDRO\",\n",
    "    \"CAMACHO\",\n",
    "    \"MOLINA\"\n",
    "}\n",
    "\n",
    "CATALOGO_UBICACIONES = {\n",
    "    \"RETIRO DIRECTO\",\n",
    "    \"SHOWROOM\",\n",
    "    \"COCHERA\",\n",
    "    \"FRONTIS\",\n",
    "    \"PATIO\",\n",
    "    \"SLA\"\n",
    "}\n",
    "\n",
    "# FUNCIONES\n",
    "def limpiar_texto(texto: str):\n",
    "    texto = texto.upper()\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto)\n",
    "    return texto.strip()\n",
    "\n",
    "def detectar_distrito(texto: str):\n",
    "    for d in sorted(CATALOGO_DISTRITOS, key=len, reverse=True):\n",
    "        if d in texto:\n",
    "            return d\n",
    "    return None\n",
    "\n",
    "def detectar_ubicacion(texto: str):\n",
    "    for u in sorted(CATALOGO_UBICACIONES, key=len, reverse=True):\n",
    "        if u in texto:\n",
    "            return u\n",
    "    return None\n",
    "\n",
    "for fila in ubicaciones_rep:\n",
    "\n",
    "    if not isinstance(fila, str) or fila.strip() == \"\":\n",
    "        continue\n",
    "\n",
    "    fila = limpiar_texto(fila)\n",
    "\n",
    "    distrito = detectar_distrito(fila)\n",
    "    ubicacion = detectar_ubicacion(fila)\n",
    "\n",
    "    if ubicacion and not distrito:\n",
    "        distrito = random.choice(list(CATALOGO_DISTRITOS))\n",
    "\n",
    "    # Registrar distrito\n",
    "    if distrito and distrito not in distritos_dict:\n",
    "        distritos_dict[distrito] = id_distrito\n",
    "        id_distrito += 1\n",
    "\n",
    "    # Registrar ubicación SOLO si tiene distrito\n",
    "    if distrito and ubicacion:\n",
    "        distrito_id = distritos_dict[distrito]\n",
    "\n",
    "        key = (ubicacion, distrito_id)\n",
    "\n",
    "        if key not in ubicaciones_dict:\n",
    "            ubicaciones_dict[key] = id_ubicacion\n",
    "            id_ubicacion += 1\n",
    "\n",
    "sql_distritos = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for nombre, id_val in distritos_dict.items():\n",
    "    nombre_esc = nombre.replace(\"'\", \"''\")\n",
    "    sql_distritos += (\n",
    "        f\"INSERT INTO distritos (id_distrito, nombre) \"\n",
    "        f\"VALUES ({id_val}, '{nombre_esc}');\\n\"\n",
    "    )\n",
    "\n",
    "sql_distritos += \"\\n-- migrate:down\\nDELETE FROM distritos;\\n\"\n",
    "\n",
    "with open(\"inserts_distritos.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_distritos)\n",
    "\n",
    "\n",
    "#UBICACIONES\n",
    "sql_ubicaciones = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for (ubicacion, distrito_id), id_val in ubicaciones_dict.items():\n",
    "    ubic_esc = ubicacion.replace(\"'\", \"''\")\n",
    "\n",
    "    sql_ubicaciones += (\n",
    "        \"INSERT INTO ubicaciones \"\n",
    "        \"(id_ubicacion, nombre, distritos_id) \"\n",
    "        f\"VALUES ({id_val}, '{ubic_esc}', {distrito_id});\\n\"\n",
    "    )\n",
    "\n",
    "sql_ubicaciones += \"\\n-- migrate:down\\nDELETE FROM ubicaciones;\\n\"\n",
    "\n",
    "with open(\"inserts_ubicaciones.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_ubicaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Campañas</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "campanas_rep = ds_ASP['CAMPAÑA']\n",
    "\n",
    "campanas_diccionario = {}\n",
    "id_campaña = 1\n",
    "\n",
    "def campaña_valida(nombre):\n",
    "    if not isinstance(nombre, str):\n",
    "        return False\n",
    "\n",
    "    nombre = nombre.strip().upper()\n",
    "\n",
    "    if nombre == \"\" or nombre in {\"SIN CAMPAÑA\", \"NO APLICA\"}:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "for c in campanas_rep:\n",
    "\n",
    "    if not campaña_valida(c):\n",
    "        continue\n",
    "\n",
    "    nombre = c.strip().upper()\n",
    "\n",
    "    # SOLO asignar ID si no existe aún\n",
    "    if nombre not in campanas_diccionario:\n",
    "        campanas_diccionario[nombre] = id_campaña\n",
    "        id_campaña += 1\n",
    "\n",
    "sql_cam = \"-- migrate:up\\n\\n\"\n",
    "\n",
    "for nombre, id_val in sorted(campanas_diccionario.items(), key=lambda x: x[1]):\n",
    "\n",
    "    descuento = 0.10\n",
    "    nombre_sql = nombre.replace(\"'\", \"''\")\n",
    "\n",
    "    sql_cam += (\n",
    "        \"INSERT INTO campañas (id_campaña, nombre, descuento) \"\n",
    "        f\"VALUES ({id_val}, '{nombre_sql}', {descuento});\\n\"\n",
    "    )\n",
    "\n",
    "sql_cam += \"\\n-- migrate:down\\nDELETE FROM campañas;\\n\"\n",
    "\n",
    "with open(\"inserts_campañas.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('NO APLICA CAMPAÑA', 1), ('CAMPAÑA OK', 2), ('NO APLICA CAMPAÑA+REVISION TALLER OK', 3), ('HACER CAMPAÑA', 4), ('NO APLICA CAMPAÑA/REVISION TALLER OK', 5), ('CAMPAÑA+REVISION OK', 6), ('CAMPAÑA 25C42 SIN PROCEDIMIENTO', 7), ('HACER CAMPAÑA/SIN PROCEDIMIENTO', 8), ('CON CAMPAÑA SIN PROCEDIMIENTO', 9), ('HACER CAMPAÑA CORREO', 10), ('CAMPAÑA 8/1', 11), ('HACER CAMPAÑA 2/1', 12), ('CAMPAÑA 7/1', 13)])\n"
     ]
    }
   ],
   "source": [
    "print(campanas_diccionario.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Recepciones</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Antes de pasar a <e>recepciones_campañas</e> se debe crear recpeciones y campañas de forma individual, luego se vinculan entre ellos</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_300\\3392632149.py:33: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  fecha = pd.to_datetime(valor, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "receps = ds_ASP[\n",
    "    [\"PLACA\",\n",
    "     \"FECHA DE INGRESO \",\n",
    "     \"FECHA TARJETA\",\n",
    "     \"FECHA PLACA\",\n",
    "     \"FECHA DE RECEPCION DEL VEHICULO\",\n",
    "     \"UBICACIÓN\",\n",
    "     \"Asesor\",\n",
    "     \"CAMPAÑA\"]\n",
    "].to_numpy()\n",
    "\n",
    "text = '-- migrate:up\\n\\n'\n",
    "\n",
    "id_recepcion = 1\n",
    "recepciones_diccionario = {}\n",
    "\n",
    "for r in receps:\n",
    "\n",
    "    placa = str(r[0]).strip().upper()\n",
    "    vehiculo_id = 'NULL'\n",
    "\n",
    "    for vid, datos in vehiculos_diccionario.items():\n",
    "        if datos[0] == placa:\n",
    "            vehiculo_id = vid\n",
    "\n",
    "    # --- FECHAS\n",
    "    def limpiar_fecha(valor):\n",
    "        if pd.isna(valor):\n",
    "            return 'NULL'\n",
    "        fecha = pd.to_datetime(valor, errors='coerce')\n",
    "        if pd.isna(fecha):\n",
    "            return 'NULL'\n",
    "        return f\"'{fecha.strftime('%Y-%m-%d')}'\"\n",
    "\n",
    "    fecha_entrega   = limpiar_fecha(r[1])\n",
    "    fecha_tarjeta   = limpiar_fecha(r[2])\n",
    "    fecha_placa     = limpiar_fecha(r[3])\n",
    "    \n",
    "    fecha_recepcion = limpiar_fecha(r[4])\n",
    "    # --- Ubicacion ---\n",
    "    ubicacion_r = 'NULL'\n",
    "    if pd.notna(r[5]):\n",
    "        ubicacion_str = str(r[5]).strip().upper()\n",
    "        for (nombre, distrito_id), mid in ubicaciones_dict.items():\n",
    "            if nombre.upper() in ubicacion_str:\n",
    "                ubicacion_r = mid\n",
    "\n",
    "    # --- ASESOR\n",
    "    asesor_str = str(r[6]).strip().upper()\n",
    "    asesor_id = asesores_diccionario.get(asesor_str, 'NULL')\n",
    "\n",
    "    # --- CAMPAÑA\n",
    "    campaña_id = \"NULL\"\n",
    "    if pd.notna(r[7]):\n",
    "        campaña_str = str(r[7]).strip().upper()\n",
    "        campaña_id = campanas_diccionario.get(campaña_str, 'NULL')\n",
    "\n",
    "    valores = [\n",
    "        fecha_entrega,\n",
    "        fecha_tarjeta,\n",
    "        fecha_placa,\n",
    "        fecha_recepcion,\n",
    "        ubicacion_r,\n",
    "        asesor_id,\n",
    "        vehiculo_id,\n",
    "        campaña_id\n",
    "    ]\n",
    "\n",
    "    if all(v == 'NULL' for v in valores):\n",
    "        continue\n",
    "\n",
    "    # --- INSERT SQL\n",
    "    text += (\n",
    "        f\"INSERT INTO recepciones \"\n",
    "        f\"(id_recepcion, fecha_entrega, fecha_tarjeta, fecha_placa, fecha_recepcion, ubicacion_id, asesor_id, vehiculo_id, campaña_id) \"\n",
    "        f\"VALUES ({id_recepcion}, {fecha_entrega}, {fecha_tarjeta}, {fecha_placa}, {fecha_recepcion}, \"\n",
    "        f\"{ubicacion_r}, {asesor_id}, {vehiculo_id}, {campaña_id});\\n\"\n",
    "    )\n",
    "\n",
    "    # --- GUARDAR DICCIONARIO\n",
    "    recepciones_diccionario[id_recepcion] = (\n",
    "        fecha_entrega,\n",
    "        fecha_tarjeta,\n",
    "        fecha_placa,\n",
    "        fecha_recepcion,\n",
    "        ubicacion_r,\n",
    "        asesor_id,\n",
    "        vehiculo_id,\n",
    "        campaña_id\n",
    "    )\n",
    "\n",
    "    id_recepcion += 1\n",
    "\n",
    "text += '\\n-- migrate:down\\nDELETE FROM recepciones;\\n'\n",
    "\n",
    "with open('inserts_recepciones.sql', 'w', encoding='utf-8') as archivo:\n",
    "    archivo.write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filtrado telefono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extraer_telefonos(texto):\n",
    "    if texto is None:\n",
    "        return None\n",
    "\n",
    "    numeros = re.sub(r'\\D', '', str(texto))\n",
    "\n",
    "    if numeros.startswith(\"51\"):\n",
    "        numeros = numeros[2:]\n",
    "\n",
    "    bloques = [numeros[i:i+9] for i in range(0, len(numeros), 9)]\n",
    "    bloques = [b for b in bloques if len(b) == 9]\n",
    "\n",
    "    return \"|\".join(bloques) if bloques else None\n",
    "\n",
    "\n",
    "telefonos_rep = ds_ASP['Celular'].to_numpy()\n",
    "\n",
    "telefonos_dict = {} \n",
    "id_telefono = 1\n",
    "sql_tel = '-- migrate:up\\n\\n'\n",
    "\n",
    "for n in telefonos_rep:\n",
    "\n",
    "    if pd.isna(n):\n",
    "        continue\n",
    "\n",
    "    lista_telefonos = extraer_telefonos(n)\n",
    "\n",
    "    if lista_telefonos is None:\n",
    "        continue\n",
    "\n",
    "    sql_tel += (\n",
    "        f\"INSERT INTO telefonos \"\n",
    "        f\"(id_telefono, numero, cliente_id) \"\n",
    "        f\"VALUES ({id_telefono}, '{lista_telefonos}');\\n\"\n",
    "    )\n",
    "\n",
    "    telefonos_dict[id_telefono] = lista_telefonos\n",
    "    id_telefono += 1\n",
    "\n",
    "\n",
    "sql_tel += \"\\n-- migrate:down\\nDELETE FROM telefonos;\\n\"\n",
    "\n",
    "with open(\"inserts_telefono.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_tel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Telefono - Cliente asociacion </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "telefonos_clientes = ds_ASP[['Celular', 'Cliente']].to_numpy()\n",
    "\n",
    "telefonosCliente_dict = {} \n",
    "id_telefono_cliente = 1\n",
    "sql_tel = '-- migrate:up\\n\\n'\n",
    "\n",
    "for n in telefonos_clientes:\n",
    "    if pd.isna(n[1]):\n",
    "        continue\n",
    "\n",
    "    nombre_cliente = str(n[1]).strip().upper()\n",
    "    cliente_id_T = None\n",
    "    for cid, (_, nombre) in clientes_dict.items():\n",
    "        if nombre.upper() in nombre_cliente:\n",
    "            cliente_id_T = cid\n",
    "            break\n",
    "\n",
    "    if cliente_id_T is None:\n",
    "        continue\n",
    "\n",
    "    if cliente_id_T in telefonosCliente_dict:\n",
    "        continue\n",
    "\n",
    "    lista_telefonos = extraer_telefonos(n[0])\n",
    "\n",
    "    if lista_telefonos is None:\n",
    "        continue\n",
    "\n",
    "    sql_tel += (\n",
    "        f\"INSERT INTO cliente_telefono \"\n",
    "        f\"(id_telefono_cliente, cliente_id) \"\n",
    "        f\"VALUES ({id_telefono_cliente}, {cliente_id_T});\\n\"\n",
    "    )\n",
    "\n",
    "    telefonosCliente_dict[cliente_id_T] = id_telefono_cliente\n",
    "    id_telefono_cliente += 1\n",
    "\n",
    "\n",
    "sql_tel += \"\\n-- migrate:down\\nDELETE FROM telefonos;\\n\"\n",
    "\n",
    "with open(\"insert_cliente_telefono.sql\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sql_tel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filtrado formato pago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diccionario generado (para usarlo después en pagos):\n",
      "{'AUTOPLAN': 1, 'AUTOPLAN VB ENTREGA+BCP': 2, 'BBVA': 3, 'BBVA BCP': 4, 'BBVA BCP INTBK': 5, 'BBVA BCP INTBK SCTBK': 6, 'BBVA BCP INTERBANK': 7, 'BBVA BCP ITBK': 8, 'BBVA BCP ITBK NIUBIZ': 9, 'BBVA BCP SCTBK': 10, 'BBVA IBK BCP': 11, 'BBVA INTBK': 12, 'BBVA INTBK BCP': 13, 'BBVA INTERBANK': 14, 'BBVA ITBK': 15, 'BBVA NIUBIZ': 16, 'BBVA SCOTBK': 17, 'BBVA SCOTIABANK': 18, 'BBVA SCOTIABANK MAF': 19, 'BBVA SCTBK BCP': 20, 'BBVA VISA': 21, 'BCP': 22, 'BCP BBVA': 23, 'BCP BBVA INTBK': 24, 'BCP BBVA MAF': 25, 'BCP INTBK': 26, 'BCP INTBK FONBIENES': 27, 'BCP INTBK NIUBIZ': 28, 'BCP INTERBANK': 29, 'BCP INTERBANK SCOTIABANK BBVA': 30, 'BCP ITBK': 31, 'BCP ITBK NIUBIZ': 32, 'BCP NIUBIZ': 33, 'BCP NIUBIZ+AUTOPLAN PEDIR VB': 34, 'BCP SANTANDER': 35, 'BCP SCOTBK': 36, 'BCP SCOTIABANK': 37, 'BCP SCTBK': 38, 'BCP SCTBK INTBK': 39, 'BCP VISA': 40, 'BCP VISA+PANDERO': 41, 'BCP+AUTOPLAN': 42, 'BCP+AUTOPLAN PEDIR VB PARA ENTREGA': 43, 'BCP+MAQUIMAS': 44, 'BCP+NIUBIZ': 45, 'BCP+PANDERO': 46, 'CREDITO BBVA': 47, 'CREDITO INTBK': 48, 'CREDITO VEHICULAR BBVA': 49, 'CREDITO VEHICULAR BCP': 50, 'CSCTBK BBVA': 51, 'IBK': 52, 'INTBK': 53, 'INTBK BBVA': 54, 'INTBK BBVA BCP': 55, 'INTBK BCP': 56, 'INTBK BCP BBVA': 57, 'INTBK SANTANDER': 58, 'INTERBANK': 59, 'INTERBANK BBVA': 60, 'INTERBANK BBVA BCP': 61, 'INTERBANK BBVA MAF': 62, 'INTERBANK BCP': 63, 'INTERBANK BCP BBVA': 64, 'INTERBANK NIUBIZ': 65, 'INTERBANK VISA': 66, 'ITBK': 67, 'LEASING BBVA': 68, 'LEASING BCP': 69, 'LEASING INTERBANK': 70, 'LEASING SCOTIABANK': 71, 'LEASING SCTBK BCP': 72, 'MAF': 73, 'MAF BBVA': 74, 'MAF BBVA BCP': 75, 'MAF BBVA NIUBIS': 76, 'MAF BCP BBVA': 77, 'MAF INTBK BBVA': 78, 'MAF+BBVA BCP': 79, 'MAF+BBVA BCP INTBK': 80, 'MAF+BBVA INTBK BCP': 81, 'MAF+BCP BBVA': 82, 'MAQUIMAS': 83, 'MAQUIMAS PEDIR PERMISO': 84, 'MAQUISITEMA BCP': 85, 'NIUBIZ': 86, 'NIUBIZ BBVA': 87, 'NIUBIZ BCP': 88, 'NIUBIZ IBK': 89, 'NIUBIZ SCOTIABANK': 90, 'NIUBIZ+RETOMA': 91, 'PANDERO': 92, 'PANDERO VISA FONBIENES': 93, 'PEDIR VB FONBIENES': 94, 'PEDIR VB PANDERO+BCP': 95, 'PEDIR VB TOTAL': 96, 'PROMOTORA OPCION+BCP': 97, 'RETOMA': 98, 'RETOMA BBVA': 99, 'RETOMA BBVA INTBK': 100, 'RETOMA BCP': 101, 'RETOMA BCP AUTOPLAN PEDI VB': 102, 'RETOMA BCP ITB NIUBIZ': 103, 'RETOMA BCP NIUBIZ': 104, 'RETOMA CREDITO VEHICULAR BBVA': 105, 'RETOMA FORD': 106, 'RETOMA INTBK': 107, 'RETOMA INTERBANK': 108, 'RETOMA MAF BBVA BCP': 109, 'RETOMA NIUBIZ': 110, 'RETOMA NIUBIZ BCP': 111, 'RETOMA SANTANDER': 112, 'RETOMA SANTANDER BBVA BCP': 113, 'RETOMA SANTANDER BCP': 114, 'RETOMA SANTANDER INTBK': 115, 'RETOMA SCOTIABANK': 116, 'RETOMA SCTBK': 117, 'RETOMA VISA': 118, 'RETOMA+BBVA': 119, 'RETOMA+BBVA BCP': 120, 'RETOMA+BBVA SCTBK': 121, 'RETOMA+BCP': 122, 'RETOMA+BCP BBVA': 123, 'RETOMA+BCP INTBK': 124, 'RETOMA+BCP ITBK': 125, 'RETOMA+BCP PEDIR VB MAQUIMAS': 126, 'RETOMA+BCP SCTBK': 127, 'RETOMA+BCP VISA': 128, 'RETOMA+BCP+SANTANDER': 129, 'RETOMA+CREDITO BBVA': 130, 'RETOMA+CREDITO VEHICULAR BBVA': 131, 'RETOMA+CREDITO VEHICULAR BCP': 132, 'RETOMA+INTBK': 133, 'RETOMA+INTERBANK': 134, 'RETOMA+INTERBANK BCP VISA': 135, 'RETOMA+LEASING BANBIF': 136, 'RETOMA+MAF BCP BBVA': 137, 'RETOMA+NIUBIZ': 138, 'RETOMA+NIUBIZ SCOTBK': 139, 'RETOMA+SANTANDER': 140, 'RETOMA+SANTANDER BBVA': 141, 'RETOMA+SANTANDER BCP': 142, 'RETOMA+SANTANDER BCP BBVA': 143, 'RETOMA+SANTANDER IBK': 144, 'RETOMA+SANTANDER ITBK': 145, 'RETOMA+SANTANDER SCOTIABANK': 146, 'RETOMA+SCOTIABANK': 147, 'RETOMA+SCTBK': 148, 'RETOMA+SCTBK INTBK': 149, 'RETOMA+VISA': 150, 'RETOMA+VISA BBVA': 151, 'SANTANDER': 152, 'SANTANDER BBVA': 153, 'SANTANDER BBVA BCP': 154, 'SANTANDER BBVA BCP+RETOMA': 155, 'SANTANDER BBVA SCTBK': 156, 'SANTANDER BCP': 157, 'SANTANDER BCP BBVA': 158, 'SANTANDER BCP BBVA SCTBK': 159, 'SANTANDER BCP ITB': 160, 'SANTANDER BCP ITBK': 161, 'SANTANDER BCP VISA': 162, 'SANTANDER INTBK': 163, 'SANTANDER INTBK BCP': 164, 'SANTANDER INTBK VISA': 165, 'SANTANDER INTERBANK': 166, 'SANTANDER ITBK': 167, 'SANTANDER NIUBIZ': 168, 'SANTANDER NIUBIZ BBVA': 169, 'SANTANDER NIUBIZ BCP': 170, 'SANTANDER RETOMA SCOTBK': 171, 'SANTANDER RETOMA+BCP': 172, 'SANTANDER SCTBK': 173, 'SANTANDER SCTBK BCP': 174, 'SANTANDER VISA': 175, 'SANTANDER+BBVA SCOT': 176, 'SANTANDER+BCP': 177, 'SANTANDER+BCP BBVA': 178, 'SANTANDER+BCP INTBK': 179, 'SANTANDER+BCP SCTBK': 180, 'SANTANDER+INTERBANK': 181, 'SANTANDER+NIUBIZ': 182, 'SANTANDER+RETOMA': 183, 'SANTANDER+RETOMA BCP': 184, 'SANTANDER+RETOMA SCOT': 185, 'SANTANDER+SCOT BBVA': 186, 'SANTANDER+SCTBK': 187, 'SCOTBK BBVA BCP': 188, 'SCOTBK BCP+PANDERO': 189, 'SCOTIABANK': 190, 'SCOTIABANK BBVA INTERBANK': 191, 'SCOTIABANK SANTANDER': 192, 'SCTBK': 193, 'VISA': 194, 'VISA NIUBIZ': 195}\n",
      "\n",
      "Total de formatos únicos: 195\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "formas_unicas = ds_ASP['FORMA DE PAGO'].dropna().unique()\n",
    "\n",
    "formas_unicas = sorted(formas_unicas)  \n",
    "\n",
    "\n",
    "\n",
    "formatos_diccionario = {}\n",
    "\n",
    "\n",
    "\n",
    "text = '-- migrate:up \\n\\n'\n",
    "\n",
    "id_counter = 1\n",
    "\n",
    "for forma in formas_unicas:\n",
    "\n",
    "    forma_escaped = str(forma).replace(\"'\", \"''\").strip()\n",
    "\n",
    "    if forma_escaped:  # evita vacíos\n",
    "\n",
    "        text += f\"INSERT INTO formaPago (id_forma_pago, nombre) VALUES ({id_counter}, '{forma_escaped}');\\n\"\n",
    "\n",
    "        formatos_diccionario[forma_escaped] = id_counter\n",
    "\n",
    "        id_counter += 1\n",
    "\n",
    "\n",
    "\n",
    "text += '\\n-- migrate:down \\n\\nDELETE FROM formatos_pago;'\n",
    "\n",
    "\n",
    "\n",
    "with open('inserts_formatos_pago.sql', 'w', encoding='utf-8') as f:\n",
    "\n",
    "    f.write(text)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Diccionario generado (para usarlo después en pagos):\")\n",
    "\n",
    "print(formatos_diccionario)\n",
    "\n",
    "print(f\"\\nTotal de formatos únicos: {len(formatos_diccionario)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrado bancos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bancos únicos encontrados: ['BANBIF', 'BBVA', 'BCP', 'INTERBANK', 'NIUBIZ', 'PANDERO', 'SANTANDER', 'SCOTIABANK', 'VISA']\n",
      "Diccionario de bancos: {'BANBIF': 1, 'BBVA': 2, 'BCP': 3, 'INTERBANK': 4, 'NIUBIZ': 5, 'PANDERO': 6, 'SANTANDER': 7, 'SCOTIABANK': 8, 'VISA': 9}\n",
      "Total de bancos únicos: 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "bancos_conocidos = [\n",
    "    'BCP', 'BBVA', 'SANTANDER', 'INTERBANK', 'INTBK', 'ITBK', 'IBK',\n",
    "    'SCOTIABANK', 'SCTBK', 'SCOTBK', 'NIUBIZ',\n",
    "    'PANDERO', 'VISA', 'BANBIF'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "normalization = {\n",
    "    'IBK': 'INTERBANK',\n",
    "    'INTBK': 'INTERBANK',\n",
    "    'ITBK': 'INTERBANK',\n",
    "    'SCOTBK': 'SCOTIABANK',\n",
    "    'SCTBK': 'SCOTIABANK',\n",
    "    'NIUBIS': 'NIUBIZ',\n",
    "}\n",
    "\n",
    "def extraer_bancos(texto):\n",
    "    if pd.isna(texto):\n",
    "        return set()\n",
    "    texto_upper = str(texto).upper()\n",
    "    encontrados = set()\n",
    "\n",
    "    for banco in bancos_conocidos:\n",
    "        if re.search(r'\\b' + re.escape(banco) + r'\\b', texto_upper) or banco in texto_upper:\n",
    "            encontrados.add(banco)\n",
    "\n",
    "    if 'LEASING' in texto_upper:\n",
    "        encontrados.add('SANTANDER')\n",
    "\n",
    "    normalized = {normalization.get(b, b) for b in encontrados}\n",
    "    return normalized\n",
    "\n",
    "\n",
    "all_bancos = set()\n",
    "for forma in ds_ASP['FORMA DE PAGO'].dropna():\n",
    "    all_bancos.update(extraer_bancos(forma))\n",
    "bancos_unicos = sorted(list(all_bancos))\n",
    "\n",
    "bancos_diccionario = {}\n",
    "text = '-- migrate:up \\n\\n'\n",
    "id_counter = 1\n",
    "for banco in bancos_unicos:\n",
    "    banco_escaped = banco.replace(\"'\", \"''\")\n",
    "    text += f\"INSERT INTO bancos (id_banco, nombre) VALUES ({id_counter}, '{banco_escaped}');\\n\"\n",
    "    bancos_diccionario[banco] = id_counter\n",
    "    id_counter += 1\n",
    "text += '\\n-- migrate:down \\n\\nDELETE FROM bancos;'\n",
    "with open('inserts_bancos.sql', 'w', encoding='utf-8') as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"Bancos únicos encontrados:\", bancos_unicos)\n",
    "print(\"Diccionario de bancos:\", bancos_diccionario)\n",
    "print(f\"Total de bancos únicos: {len(bancos_unicos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro pagos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificación diccionarios:\n",
      "  Recepciones: 1258\n",
      "  Formatos:    195\n",
      "  Bancos:      9\n",
      "\n",
      "Todos los diccionarios están listos → procediendo a generar pagos...\n",
      "\n",
      "Resultado final:\n",
      "Pagos generados: 1004\n",
      "Errores / filas saltadas: 254\n",
      "Archivo creado: inserts_pagos.sql\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "print(\"Verificación diccionarios:\")\n",
    "print(f\"  Recepciones: {len(recepciones_diccionario) if 'recepciones_diccionario' in globals() else 'NO EXISTE'}\")\n",
    "print(f\"  Formatos:    {len(formatos_diccionario) if 'formatos_diccionario' in globals() else 'NO EXISTE'}\")\n",
    "print(f\"  Bancos:      {len(bancos_diccionario) if 'bancos_diccionario' in globals() else 'NO EXISTE'}\")\n",
    "\n",
    "if not all([\n",
    "    'recepciones_diccionario' in globals() and len(recepciones_diccionario) > 0,\n",
    "    'formatos_diccionario' in globals() and len(formatos_diccionario) > 0,\n",
    "    'bancos_diccionario' in globals() and len(bancos_diccionario) > 0\n",
    "]):\n",
    "    print(\"\\n¡Faltan diccionarios! Ejecuta primero los códigos de recepciones, formatos y bancos.\")\n",
    "else:\n",
    "    print(\"\\nTodos los diccionarios están listos → procediendo a generar pagos...\")\n",
    "\n",
    "def obtener_banco_principal(forma_str):\n",
    "    if not isinstance(forma_str, str):\n",
    "        return 'BCP'\n",
    "    texto = forma_str.upper()\n",
    "    orden_prioridad = ['INTERBANK', 'SCOTIABANK', 'BBVA', 'BCP', 'SANTANDER', 'NIUBIZ']\n",
    "    for banco in orden_prioridad:\n",
    "        if banco in texto:\n",
    "            return banco\n",
    "    for banco in bancos_diccionario:\n",
    "        if banco in texto:\n",
    "            return banco\n",
    "    return 'BCP'\n",
    "\n",
    "\n",
    "text = '-- migrate:up \\n\\n'\n",
    "id_pago = 1\n",
    "errores = 0\n",
    "\n",
    "for idx, row in ds_ASP.iterrows():\n",
    "    if not recepciones_diccionario:\n",
    "        errores += 1\n",
    "        continue\n",
    "\n",
    "    recepcion_id = (id_pago % len(recepciones_diccionario)) + 1  \n",
    "    forma_raw = row.get('FORMA DE PAGO')\n",
    "    forma_str = str(forma_raw).strip() if pd.notna(forma_raw) else ''\n",
    "    forma_escaped = forma_str.replace(\"'\", \"''\")\n",
    "\n",
    "    formas_pago_id = formatos_diccionario.get(forma_escaped)\n",
    "    if formas_pago_id is None:\n",
    "        errores += 1\n",
    "        continue\n",
    "\n",
    "    \n",
    "    banco_nombre = obtener_banco_principal(forma_str)\n",
    "    bancos_id = bancos_diccionario.get(banco_nombre)\n",
    "    if bancos_id is None:\n",
    "        errores += 1\n",
    "        continue\n",
    "\n",
    "    monto = round(random.uniform(8000, 85000), 2)\n",
    "\n",
    "    text += (\n",
    "        f\"INSERT INTO pagos (id_pago, recepcion_id, monto, bancos_id, formas_pago_id) \"\n",
    "        f\"VALUES ({id_pago}, {recepcion_id}, {monto}, {bancos_id}, {formas_pago_id});\\n\"\n",
    "    )\n",
    "\n",
    "    id_pago += 1\n",
    "\n",
    "text += '\\n-- migrate:down \\n\\nDELETE FROM pagos;\\n'\n",
    "\n",
    "with open('inserts_pagos.sql', 'w', encoding='utf-8') as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(f\"\\nResultado final:\")\n",
    "print(f\"Pagos generados: {id_pago - 1}\")\n",
    "print(f\"Errores / filas saltadas: {errores}\")\n",
    "print(\"Archivo creado: inserts_pagos.sql\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
